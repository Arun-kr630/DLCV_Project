{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teken Pretrained Resnet as Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/arunkumar12/miniconda3/envs/torch/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/data/home/arunkumar12/miniconda3/envs/torch/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Extracting Fingerprints: 100%|██████████| 5001/5001 [02:36<00:00, 32.02it/s]\n",
      "Extracting Fingerprints: 100%|██████████| 1545/1545 [01:14<00:00, 20.70it/s]\n",
      "Extracting Fingerprints: 100%|██████████| 654/654 [00:21<00:00, 29.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.6972\n",
      "Epoch 2/20, Loss: 0.6945\n",
      "Epoch 3/20, Loss: 0.6919\n",
      "Epoch 4/20, Loss: 0.6893\n",
      "Epoch 5/20, Loss: 0.6869\n",
      "Epoch 6/20, Loss: 0.6844\n",
      "Epoch 7/20, Loss: 0.6820\n",
      "Epoch 8/20, Loss: 0.6795\n",
      "Epoch 9/20, Loss: 0.6771\n",
      "Epoch 10/20, Loss: 0.6747\n",
      "Epoch 11/20, Loss: 0.6722\n",
      "Epoch 12/20, Loss: 0.6698\n",
      "Epoch 13/20, Loss: 0.6674\n",
      "Epoch 14/20, Loss: 0.6649\n",
      "Epoch 15/20, Loss: 0.6625\n",
      "Epoch 16/20, Loss: 0.6601\n",
      "Epoch 17/20, Loss: 0.6577\n",
      "Epoch 18/20, Loss: 0.6553\n",
      "Epoch 19/20, Loss: 0.6529\n",
      "Epoch 20/20, Loss: 0.6505\n",
      "Validation Set:\n",
      "Accuracy: 66.57%\n",
      "Test Set:\n",
      "Accuracy: 58.47%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set device to GPU 1\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Paths\n",
    "DATASET_PATH = \"dataset\"\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "# Transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "def get_dataloader(split):\n",
    "    dataset_paths = []\n",
    "    for dataset in [\"Data Set 1\", \"Data Set 2\", \"Data Set 3\", \"Data Set 4\"]:\n",
    "        dataset_paths.append(os.path.join(DATASET_PATH, dataset, split))\n",
    "    \n",
    "    datasets_list = [datasets.ImageFolder(path, transform=transform) for path in dataset_paths]\n",
    "    combined_dataset = torch.utils.data.ConcatDataset(datasets_list)\n",
    "    \n",
    "    return DataLoader(combined_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "\n",
    "train_loader = get_dataloader(\"train\")\n",
    "val_loader = get_dataloader(\"validation\")\n",
    "test_loader = get_dataloader(\"test\")\n",
    "\n",
    "# Fingerprint Extraction Model (ResNet-18)\n",
    "class FingerprintExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FingerprintExtractor, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        self.model.fc = nn.Identity()  # Remove final layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "fingerprint_extractor = FingerprintExtractor().to(device)\n",
    "\n",
    "# Extract Fingerprints\n",
    "def extract_fingerprints(dataloader, model):\n",
    "    model.eval()\n",
    "    fingerprints = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(dataloader, desc=\"Extracting Fingerprints\"):\n",
    "            images = images.to(device)\n",
    "            features = model(images).cpu().numpy()\n",
    "            fingerprints.append(features)\n",
    "            labels.append(targets.numpy())\n",
    "    return np.vstack(fingerprints), np.hstack(labels)\n",
    "\n",
    "train_fingerprints, train_labels = extract_fingerprints(train_loader, fingerprint_extractor)\n",
    "val_fingerprints, val_labels = extract_fingerprints(val_loader, fingerprint_extractor)\n",
    "test_fingerprints, test_labels = extract_fingerprints(test_loader, fingerprint_extractor)\n",
    "\n",
    "# Save fingerprints\n",
    "np.save(\"train_fingerprints.npy\", train_fingerprints)\n",
    "np.save(\"train_labels.npy\", train_labels)\n",
    "np.save(\"val_fingerprints.npy\", val_fingerprints)\n",
    "np.save(\"val_labels.npy\", val_labels)\n",
    "np.save(\"test_fingerprints.npy\", test_fingerprints)\n",
    "np.save(\"test_labels.npy\", test_labels)\n",
    "\n",
    "# Classifier Model (MLP)\n",
    "class FingerprintClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(FingerprintClassifier, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 2)  # Real vs Fake\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "classifier = FingerprintClassifier(input_dim=train_fingerprints.shape[1]).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-4)\n",
    "\n",
    "# Convert fingerprints to PyTorch tensors\n",
    "def get_tensor_data(fingerprints, labels):\n",
    "    return torch.tensor(fingerprints, dtype=torch.float32).to(device), torch.tensor(labels, dtype=torch.long).to(device)\n",
    "\n",
    "train_X, train_Y = get_tensor_data(train_fingerprints, train_labels)\n",
    "val_X, val_Y = get_tensor_data(val_fingerprints, val_labels)\n",
    "test_X, test_Y = get_tensor_data(test_fingerprints, test_labels)\n",
    "\n",
    "# Train Classifier\n",
    "def train_classifier(model, optimizer, criterion, epochs=20):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(train_X)\n",
    "        loss = criterion(outputs, train_Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "train_classifier(classifier, optimizer, criterion)\n",
    "\n",
    "# Evaluate Classifier\n",
    "def evaluate_classifier(model, X, Y):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X).argmax(dim=1)\n",
    "        accuracy = (predictions == Y).float().mean()\n",
    "        print(f\"Accuracy: {accuracy.item() * 100:.2f}%\")\n",
    "\n",
    "print(\"Validation Set:\")\n",
    "evaluate_classifier(classifier, val_X, val_Y)\n",
    "print(\"Test Set:\")\n",
    "evaluate_classifier(classifier, test_X, test_Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning on pretrained resnet as classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.0917\n",
      "Epoch 2/20, Loss: 0.0432\n",
      "Epoch 3/20, Loss: 0.0305\n",
      "Epoch 4/20, Loss: 0.0232\n",
      "Epoch 5/20, Loss: 0.0199\n",
      "Epoch 6/20, Loss: 0.0166\n",
      "Epoch 7/20, Loss: 0.0145\n",
      "Epoch 8/20, Loss: 0.0134\n",
      "Epoch 9/20, Loss: 0.0114\n",
      "Epoch 10/20, Loss: 0.0110\n",
      "Epoch 11/20, Loss: 0.0094\n",
      "Epoch 12/20, Loss: 0.0093\n",
      "Epoch 13/20, Loss: 0.0077\n",
      "Epoch 14/20, Loss: 0.0084\n",
      "Epoch 15/20, Loss: 0.0068\n",
      "Epoch 16/20, Loss: 0.0071\n",
      "Epoch 17/20, Loss: 0.0067\n",
      "Epoch 18/20, Loss: 0.0060\n",
      "Epoch 19/20, Loss: 0.0057\n",
      "Epoch 20/20, Loss: 0.0054\n",
      "Validation Set:\n",
      "Accuracy: 98.18%\n",
      "Test Set:\n",
      "Accuracy: 93.59%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# Set device to GPU 1\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Paths\n",
    "DATASET_PATH = \"dataset\"\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "# Transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "def get_dataloader(split):\n",
    "    dataset_paths = []\n",
    "    for dataset in [\"Data Set 1\", \"Data Set 2\", \"Data Set 3\", \"Data Set 4\"]:\n",
    "        dataset_paths.append(os.path.join(DATASET_PATH, dataset, split))\n",
    "    \n",
    "    datasets_list = [datasets.ImageFolder(path, transform=transform) for path in dataset_paths]\n",
    "    combined_dataset = torch.utils.data.ConcatDataset(datasets_list)\n",
    "    \n",
    "    return DataLoader(combined_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "\n",
    "train_loader = get_dataloader(\"train\")\n",
    "val_loader = get_dataloader(\"validation\")\n",
    "test_loader = get_dataloader(\"test\")\n",
    "\n",
    "# ResNet Model for Fake Image Detection\n",
    "class FakeImageClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FakeImageClassifier, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, 2)  # Real vs Fake\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = FakeImageClassifier().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Train Model\n",
    "def train_model(model, train_loader, criterion, optimizer, epochs=20):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "train_model(model, train_loader, criterion, optimizer)\n",
    "\n",
    "# Evaluate Model\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    print(f\"Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "print(\"Validation Set:\")\n",
    "evaluate_model(model, val_loader)\n",
    "print(\"Test Set:\")\n",
    "evaluate_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experment we have taken resnet50, efficientnet_b0, and vit_b_16 as feature extractor then we have train different classifier to identify the wellness of features by achieving better accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/arunkumar12/miniconda3/envs/torch/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/data/home/arunkumar12/miniconda3/envs/torch/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /data/home/arunkumar12/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:03<00:00, 29.8MB/s]\n",
      "/data/home/arunkumar12/miniconda3/envs/torch/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /data/home/arunkumar12/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
      "100%|██████████| 20.5M/20.5M [00:01<00:00, 17.5MB/s]\n",
      "/data/home/arunkumar12/miniconda3/envs/torch/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /data/home/arunkumar12/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n",
      "100%|██████████| 330M/330M [00:09<00:00, 36.7MB/s] \n",
      "Processing DataSet3/train/real: 100%|██████████| 20000/20000 [45:43<00:00,  7.29it/s]  \n",
      "Processing DataSet3/train/fake: 100%|██████████| 20000/20000 [59:38<00:00,  5.59it/s]  \n",
      "Processing DataSet3/test/real: 100%|██████████| 2603/2603 [05:13<00:00,  8.32it/s]\n",
      "Processing DataSet3/test/fake: 100%|██████████| 2623/2623 [05:14<00:00,  8.33it/s]\n",
      "Processing DataSet4/train/real: 100%|██████████| 20000/20000 [42:10<00:00,  7.90it/s]  \n",
      "Processing DataSet4/train/fake: 100%|██████████| 20000/20000 [41:52<00:00,  7.96it/s] \n",
      "Processing DataSet4/test/real: 100%|██████████| 2603/2603 [06:07<00:00,  7.09it/s]\n",
      "Processing DataSet4/test/fake: 100%|██████████| 2623/2623 [05:13<00:00,  8.38it/s]\n",
      "Processing DataSet1/train/real: 100%|██████████| 20001/20001 [46:07<00:00,  7.23it/s]  \n",
      "Processing DataSet1/train/fake: 100%|██████████| 20001/20001 [1:41:53<00:00,  3.27it/s]  \n",
      "Processing DataSet1/test/real: 100%|██████████| 2604/2604 [14:44<00:00,  2.94it/s]\n",
      "Processing DataSet1/test/fake: 100%|██████████| 2623/2623 [14:49<00:00,  2.95it/s]\n",
      "Processing DataSet2/train/real: 100%|██████████| 20000/20000 [1:52:06<00:00,  2.97it/s]  \n",
      "Processing DataSet2/train/fake: 100%|██████████| 20000/20000 [1:43:24<00:00,  3.22it/s]  \n",
      "Processing DataSet2/test/real: 100%|██████████| 2603/2603 [12:45<00:00,  3.40it/s]\n",
      "Processing DataSet2/test/fake: 100%|██████████| 2623/2623 [12:48<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define dataset path\n",
    "dataset_path = \"dataset/\"  # Update with your dataset path\n",
    "\n",
    "# Define device (use CUDA 5 if available)\n",
    "device = torch.device(\"cuda:5\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define models for feature extraction\n",
    "models_dict = {\n",
    "    \"resnet50\": models.resnet50(pretrained=True).to(device),\n",
    "    \"efficientnet_b0\": models.efficientnet_b0(pretrained=True).to(device),\n",
    "    \"vit_b_16\": models.vit_b_16(pretrained=True).to(device)\n",
    "}\n",
    "\n",
    "# Set models to evaluation mode\n",
    "for model in models_dict.values():\n",
    "    model.eval()\n",
    "\n",
    "# Image transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Function to extract features\n",
    "def extract_features(model, img_path):\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        features = model(image)\n",
    "    return features.cpu().numpy().flatten()\n",
    "\n",
    "# Loop over datasets and extract features\n",
    "feature_data = []\n",
    "labels = []\n",
    "\n",
    "for dataset in os.listdir(dataset_path):\n",
    "    dataset_folder = os.path.join(dataset_path, dataset)\n",
    "    if os.path.isdir(dataset_folder):\n",
    "        for split in [\"train\", \"test\"]:  # Adjusted for dataset structure\n",
    "            split_folder = os.path.join(dataset_folder, split)\n",
    "            if os.path.isdir(split_folder):\n",
    "                for label in [\"real\", \"fake\"]:\n",
    "                    image_folder = os.path.join(split_folder, label)\n",
    "                    if os.path.isdir(image_folder):\n",
    "                        for img_name in tqdm(os.listdir(image_folder), desc=f\"Processing {dataset}/{split}/{label}\"):\n",
    "                            img_path = os.path.join(image_folder, img_name)\n",
    "                            \n",
    "                            feature_vector = []\n",
    "                            for model_name, model in models_dict.items():\n",
    "                                features = extract_features(model, img_path)\n",
    "                                feature_vector.extend(features)\n",
    "                            \n",
    "                            feature_data.append(feature_vector)\n",
    "                            labels.append(0 if label == \"real\" else 1)\n",
    "\n",
    "# Save features and labels\n",
    "np.save(\"features.npy\", np.array(feature_data))\n",
    "np.save(\"labels.npy\", np.array(labels))\n",
    "print(\"Feature extraction completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP with 3 hidden layer, dropout and batchnormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.7054\n",
      "Epoch [2/20], Loss: 0.7701\n",
      "Epoch [3/20], Loss: 0.5784\n",
      "Epoch [4/20], Loss: 0.6119\n",
      "Epoch [5/20], Loss: 0.5625\n",
      "Epoch [6/20], Loss: 0.5229\n",
      "Epoch [7/20], Loss: 0.5221\n",
      "Epoch [8/20], Loss: 0.5169\n",
      "Epoch [9/20], Loss: 0.4979\n",
      "Epoch [10/20], Loss: 0.4802\n",
      "Epoch [11/20], Loss: 0.4737\n",
      "Epoch [12/20], Loss: 0.4708\n",
      "Epoch [13/20], Loss: 0.4618\n",
      "Epoch [14/20], Loss: 0.4514\n",
      "Epoch [15/20], Loss: 0.4437\n",
      "Epoch [16/20], Loss: 0.4374\n",
      "Epoch [17/20], Loss: 0.4336\n",
      "Epoch [18/20], Loss: 0.4279\n",
      "Epoch [19/20], Loss: 0.4186\n",
      "Epoch [20/20], Loss: 0.4115\n",
      "Test Accuracy: 78.78%\n",
      "Training and evaluation completed!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, optim\n",
    "\n",
    "# Define device (use CUDA 5 if available)\n",
    "device = torch.device(\"cuda:6\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load extracted features and labels\n",
    "feature_data = np.load(\"features.npy\")\n",
    "labels = np.load(\"labels.npy\")\n",
    "\n",
    "# Normalize features\n",
    "feature_data = (feature_data - np.mean(feature_data, axis=0)) / np.std(feature_data, axis=0)\n",
    "\n",
    "# Split dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train, X_test = torch.tensor(X_train, dtype=torch.float32).to(device), torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_train, y_test = torch.tensor(y_train, dtype=torch.long).to(device), torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "# Define MLP classifier\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 1024)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.fc3 = nn.Linear(512, 2)  # Binary classification\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "input_size = X_train.shape[1]\n",
    "model = MLPClassifier(input_size).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-5)\n",
    "\n",
    "# Training loop\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test)\n",
    "    predictions = torch.argmax(outputs, dim=1)\n",
    "    accuracy = (predictions == y_test).float().mean()\n",
    "    print(f\"Test Accuracy: {accuracy.item() * 100:.2f}%\")\n",
    "\n",
    "print(\"Training and evaluation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.7186, Train Accuracy: 49.98%, Test Accuracy: 61.41%\n",
      "Epoch [2/50], Loss: 0.7600, Train Accuracy: 66.11%, Test Accuracy: 55.15%\n",
      "Epoch [3/50], Loss: 0.5789, Train Accuracy: 69.31%, Test Accuracy: 51.95%\n",
      "Epoch [4/50], Loss: 0.6065, Train Accuracy: 66.41%, Test Accuracy: 61.16%\n",
      "Epoch [5/50], Loss: 0.5461, Train Accuracy: 72.10%, Test Accuracy: 71.89%\n",
      "Epoch [6/50], Loss: 0.5249, Train Accuracy: 73.46%, Test Accuracy: 73.41%\n",
      "Epoch [7/50], Loss: 0.5225, Train Accuracy: 73.42%, Test Accuracy: 73.60%\n",
      "Epoch [8/50], Loss: 0.5067, Train Accuracy: 74.71%, Test Accuracy: 73.52%\n",
      "Epoch [9/50], Loss: 0.4853, Train Accuracy: 76.38%, Test Accuracy: 72.78%\n",
      "Epoch [10/50], Loss: 0.4757, Train Accuracy: 77.02%, Test Accuracy: 72.95%\n",
      "Epoch [11/50], Loss: 0.4707, Train Accuracy: 77.29%, Test Accuracy: 74.48%\n",
      "Epoch [12/50], Loss: 0.4582, Train Accuracy: 78.22%, Test Accuracy: 76.54%\n",
      "Epoch [13/50], Loss: 0.4433, Train Accuracy: 78.93%, Test Accuracy: 77.77%\n",
      "Epoch [14/50], Loss: 0.4379, Train Accuracy: 79.17%, Test Accuracy: 78.70%\n",
      "Epoch [15/50], Loss: 0.4315, Train Accuracy: 79.58%, Test Accuracy: 79.13%\n",
      "Epoch [16/50], Loss: 0.4230, Train Accuracy: 80.15%, Test Accuracy: 78.84%\n",
      "Epoch [17/50], Loss: 0.4136, Train Accuracy: 80.67%, Test Accuracy: 78.37%\n",
      "Epoch [18/50], Loss: 0.4059, Train Accuracy: 81.04%, Test Accuracy: 78.22%\n",
      "Epoch [19/50], Loss: 0.4013, Train Accuracy: 81.32%, Test Accuracy: 78.77%\n",
      "Epoch [20/50], Loss: 0.3956, Train Accuracy: 81.63%, Test Accuracy: 80.07%\n",
      "Epoch [21/50], Loss: 0.3873, Train Accuracy: 82.18%, Test Accuracy: 81.22%\n",
      "Epoch [22/50], Loss: 0.3812, Train Accuracy: 82.52%, Test Accuracy: 81.82%\n",
      "Epoch [23/50], Loss: 0.3777, Train Accuracy: 82.72%, Test Accuracy: 82.06%\n",
      "Epoch [24/50], Loss: 0.3710, Train Accuracy: 83.07%, Test Accuracy: 82.06%\n",
      "Epoch [25/50], Loss: 0.3648, Train Accuracy: 83.42%, Test Accuracy: 82.06%\n",
      "Epoch [26/50], Loss: 0.3599, Train Accuracy: 83.70%, Test Accuracy: 82.52%\n",
      "Epoch [27/50], Loss: 0.3551, Train Accuracy: 84.05%, Test Accuracy: 83.23%\n",
      "Epoch [28/50], Loss: 0.3499, Train Accuracy: 84.28%, Test Accuracy: 83.75%\n",
      "Epoch [29/50], Loss: 0.3446, Train Accuracy: 84.48%, Test Accuracy: 84.06%\n",
      "Epoch [30/50], Loss: 0.3415, Train Accuracy: 84.69%, Test Accuracy: 84.31%\n",
      "Epoch [31/50], Loss: 0.3358, Train Accuracy: 84.95%, Test Accuracy: 84.51%\n",
      "Epoch [32/50], Loss: 0.3307, Train Accuracy: 85.33%, Test Accuracy: 84.66%\n",
      "Epoch [33/50], Loss: 0.3275, Train Accuracy: 85.46%, Test Accuracy: 85.01%\n",
      "Epoch [34/50], Loss: 0.3239, Train Accuracy: 85.69%, Test Accuracy: 85.27%\n",
      "Epoch [35/50], Loss: 0.3183, Train Accuracy: 86.06%, Test Accuracy: 85.37%\n",
      "Epoch [36/50], Loss: 0.3146, Train Accuracy: 86.16%, Test Accuracy: 85.47%\n",
      "Epoch [37/50], Loss: 0.3118, Train Accuracy: 86.24%, Test Accuracy: 85.70%\n",
      "Epoch [38/50], Loss: 0.3063, Train Accuracy: 86.52%, Test Accuracy: 85.74%\n",
      "Epoch [39/50], Loss: 0.3038, Train Accuracy: 86.65%, Test Accuracy: 85.96%\n",
      "Epoch [40/50], Loss: 0.2991, Train Accuracy: 86.87%, Test Accuracy: 86.16%\n",
      "Epoch [41/50], Loss: 0.2953, Train Accuracy: 87.16%, Test Accuracy: 86.07%\n",
      "Epoch [42/50], Loss: 0.2927, Train Accuracy: 87.33%, Test Accuracy: 86.29%\n",
      "Epoch [43/50], Loss: 0.2877, Train Accuracy: 87.53%, Test Accuracy: 86.44%\n",
      "Epoch [44/50], Loss: 0.2849, Train Accuracy: 87.70%, Test Accuracy: 86.57%\n",
      "Epoch [45/50], Loss: 0.2808, Train Accuracy: 88.00%, Test Accuracy: 86.63%\n",
      "Epoch [46/50], Loss: 0.2771, Train Accuracy: 88.07%, Test Accuracy: 86.71%\n",
      "Epoch [47/50], Loss: 0.2744, Train Accuracy: 88.20%, Test Accuracy: 86.82%\n",
      "Epoch [48/50], Loss: 0.2702, Train Accuracy: 88.39%, Test Accuracy: 87.02%\n",
      "Epoch [49/50], Loss: 0.2669, Train Accuracy: 88.64%, Test Accuracy: 87.09%\n",
      "Epoch [50/50], Loss: 0.2635, Train Accuracy: 88.75%, Test Accuracy: 87.11%\n",
      "Final Test Accuracy: 87.11%\n",
      "Training and evaluation completed!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, optim\n",
    "\n",
    "# Define device (use CUDA 5 if available)\n",
    "device = torch.device(\"cuda:6\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load extracted features and labels\n",
    "feature_data = np.load(\"features.npy\")\n",
    "labels = np.load(\"labels.npy\")\n",
    "\n",
    "# Normalize features\n",
    "feature_data = (feature_data - np.mean(feature_data, axis=0)) / np.std(feature_data, axis=0)\n",
    "\n",
    "# Split dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train, X_test = torch.tensor(X_train, dtype=torch.float32).to(device), torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_train, y_test = torch.tensor(y_train, dtype=torch.long).to(device), torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "# Define MLP classifier\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 2048)\n",
    "        self.bn1 = nn.BatchNorm1d(2048)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(2048, 1024)\n",
    "        self.bn2 = nn.BatchNorm1d(1024)\n",
    "        self.fc3 = nn.Linear(1024, 512)\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.fc4 = nn.Linear(512, 2)  # Binary classification\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "input_size = X_train.shape[1]\n",
    "model = MLPClassifier(input_size).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0003, weight_decay=1e-4)\n",
    "\n",
    "# Training loop\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Calculate training accuracy\n",
    "    predictions = torch.argmax(outputs, dim=1)\n",
    "    train_accuracy = (predictions == y_train).float().mean().item()\n",
    "    \n",
    "    # Evaluate on test set at each epoch\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test)\n",
    "        test_predictions = torch.argmax(test_outputs, dim=1)\n",
    "        test_accuracy = (test_predictions == y_test).float().mean().item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}, Train Accuracy: {train_accuracy * 100:.2f}%, Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Final Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test)\n",
    "    predictions = torch.argmax(outputs, dim=1)\n",
    "    accuracy = (predictions == y_test).float().mean()\n",
    "    print(f\"Final Test Accuracy: {accuracy.item() * 100:.2f}%\")\n",
    "\n",
    "print(\"Training and evaluation completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/arunkumar12/miniconda3/envs/torch/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 84.57%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load extracted features and labels\n",
    "feature_data = np.load(\"features.npy\")\n",
    "labels = np.load(\"labels.npy\")\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "feature_data = scaler.fit_transform(feature_data)\n",
    "\n",
    "# Split dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define and train Logistic Regression classifier\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "print(f\"Logistic Regression Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 66.25%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load extracted features and labels\n",
    "feature_data = np.load(\"features.npy\")\n",
    "labels = np.load(\"labels.npy\")\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "feature_data = scaler.fit_transform(feature_data)\n",
    "\n",
    "# Split dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define and train Decision Tree classifier\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = dt_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "print(f\"Decision Tree Accuracy: {accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
